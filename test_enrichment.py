#!/usr/bin/env python3
"""
Script de test pour v√©rifier l'installation et le fonctionnement de l'enrichissement
"""

import sys
from pathlib import Path

# Ajouter le r√©pertoire au path
sys.path.insert(0, str(Path(__file__).parent))

from config import Config
from enrichment_service import EnrichmentService


def test_enrichment():
    """Test basique de l'enrichissement"""
    print("üß™ Test de l'enrichissement Vocalyx\n")
    
    # Afficher les informations Python
    print(f"üêç Python: {sys.executable}")
    print(f"   Version: {sys.version.split()[0]}\n")
    
    # V√©rifier que llama-cpp-python est install√©
    try:
        import llama_cpp
        version = getattr(llama_cpp, '__version__', 'unknown')
        print(f"‚úÖ llama-cpp-python est install√© (version: {version})\n")
    except ImportError as e:
        print("‚ùå llama-cpp-python n'est pas install√©")
        print(f"   Erreur: {e}")
        print("\nüí° Pour installer :")
        print(f"   {sys.executable} -m pip install llama-cpp-python")
        print("\n   Ou avec optimisations CPU (Linux) :")
        print("   CMAKE_ARGS=\"-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\" pip3 install llama-cpp-python")
        print("\n   Voir INSTALL_LLAMA.md pour plus de d√©tails\n")
        return False
    
    # Charger la configuration
    print("1Ô∏è‚É£ Chargement de la configuration...")
    try:
        config = Config()
        print(f"   ‚úÖ Configuration charg√©e")
        print(f"   - Mod√®le: {config.llm_model}")
        print(f"   - Threads: {config.llm_n_threads or 'auto'}")
        print(f"   - Contexte: {config.llm_n_ctx}")
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        return False
    
    # Initialiser le service
    print("\n2Ô∏è‚É£ Initialisation du service d'enrichissement...")
    try:
        service = EnrichmentService(config)
        print(f"   ‚úÖ Service initialis√©")
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        return False
    
    # Test d'enrichissement
    print("\n3Ô∏è‚É£ Test d'enrichissement d'un texte...")
    test_text = "Bonjour comment allez vous aujourd'hui"
    print(f"   Texte original: {test_text}")
    
    try:
        enriched = service.enrich_text(test_text)
        print(f"   Texte enrichi: {enriched}")
        
        if enriched == test_text:
            print("   ‚ö†Ô∏è  Le texte n'a pas √©t√© enrichi")
            print("   üí° Cela peut indiquer que le mod√®le n'a pas pu √™tre charg√©")
            print("   üí° V√©rifiez que llama-cpp-python est install√© et que le mod√®le existe")
            # Ne pas √©chouer le test, mais avertir
        else:
            print("   ‚úÖ Enrichissement r√©ussi !")
            
    except ImportError as e:
        print(f"   ‚ùå Erreur d'importation: {e}")
        print("   üí° Installez llama-cpp-python avec: pip3 install llama-cpp-python")
        return False
    except Exception as e:
        print(f"   ‚ùå Erreur lors de l'enrichissement: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test avec segments
    print("\n4Ô∏è‚É£ Test d'enrichissement de segments...")
    test_segments = [
        {"text": "Premier segment de transcription", "start": 0.0, "end": 2.5},
        {"text": "Deuxi√®me segment avec du contenu", "start": 2.5, "end": 5.0},
    ]
    
    try:
        enriched_segments = service.enrich_segments(test_segments)
        print(f"   ‚úÖ {len(enriched_segments)} segments enrichis")
        
        # V√©rifier que l'enrichissement a r√©ellement fonctionn√©
        all_enriched = True
        for i, seg in enumerate(enriched_segments):
            enriched_text = seg.get('enriched_text', seg.get('text', ''))
            original_text = seg.get('text', '')
            is_enriched = enriched_text != original_text
            all_enriched = all_enriched and is_enriched
            status = "‚úÖ" if is_enriched else "‚ö†Ô∏è"
            print(f"   {status} Segment {i+1}: {enriched_text[:50]}...")
        
        if not all_enriched:
            print("   ‚ö†Ô∏è  Certains segments n'ont pas √©t√© enrichis")
            print("   üí° V√©rifiez que le mod√®le est correctement charg√©")
    except ImportError as e:
        print(f"   ‚ùå Erreur d'importation: {e}")
        print("   üí° Installez llama-cpp-python avec: pip3 install llama-cpp-python")
        return False
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\n‚úÖ Tous les tests sont pass√©s avec succ√®s !")
    return True


if __name__ == '__main__':
    success = test_enrichment()
    sys.exit(0 if success else 1)
