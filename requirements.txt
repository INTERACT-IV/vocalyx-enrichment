# Vocalyx Enrichment Worker - Dependencies

# Celery
celery>=5.3.0
redis>=5.0.0

# API Client
requests>=2.31.0

# System monitoring
psutil>=5.9.0

# Optional: Colored logging
colorama>=0.4.6

# LLM Libraries - CPU-optimized
# llama-cpp-python: Backend principal pour modèles GGUF quantisés (CPU-only)
# Installation recommandée avec optimisations CPU:
#   CMAKE_ARGS="-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS" pip install llama-cpp-python
#   ou pour Mac M1/M2:
#   CMAKE_ARGS="-DLLAMA_METAL=ON" pip install llama-cpp-python
llama-cpp-python>=0.2.0

# Hugging Face Hub: Pour télécharger les modèles GGUF
huggingface-hub>=0.19.0

# Optional: Pour meilleures performances CPU (OpenBLAS)
# numpy>=1.24.0  # Dépendance de llama-cpp-python
